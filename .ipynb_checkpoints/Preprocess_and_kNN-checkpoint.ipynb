{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'listing_url', 'scrape_id', 'last_scraped', 'name', 'summary', 'space', 'description', 'experiences_offered', 'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules', 'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'street', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'city', 'state', 'zipcode', 'market', 'smart_location', 'country_code', 'country', 'latitude', 'longitude', 'is_location_exact', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities', 'square_feet', 'price', 'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'requires_license', 'license', 'jurisdiction_names', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', 'calculated_host_listings_count', 'reviews_per_month']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjhuynh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('Airbnb_data/listings_SanFan.csv')\n",
    "print(list(df))\n",
    "# u'zipcode',u'location_price',,u'instant_bookable', u'host_is_superhost',u'host_response_rate',\n",
    "selected_features = [u'price',u'accommodates',u'host_response_time',\n",
    "       u'bathrooms', u'bedrooms', u'beds',u'security_deposit', u'cleaning_fee', u'guests_included',\n",
    "       u'extra_people', u'minimum_nights', u'maximum_nights',u'guests_included',  \n",
    "       u'availability_365','latitude','longitude', 'zipcode',u'location_price',u'instant_bookable', u'host_is_superhost',u'host_response_rate',\n",
    "       u'number_of_reviews', u'review_scores_rating',u'review_scores_cleanliness', u'review_scores_checkin',\n",
    "       u'review_scores_communication', u'review_scores_location',\n",
    "       u'review_scores_value', u'house_rules',u'amenities','bed_type', 'room_type', 'cancellation_policy', 'property_type']\n",
    "df = df.loc[:, selected_features]\n",
    "# df.apply(lambda x:x.fillna(x.value_counts().index[0], inplace=True))\n",
    "# df.fillna(method = 'backfill', inplace = True)\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['60625', '60640', nan, '60613', '60618', '60659', '60615', '60637',\n",
       "       '60626', '60645', '60660', '60630', '60646', '60634', '60647',\n",
       "       '60622', '60614', '60642', '60612', '60654', '60661', '60651',\n",
       "       '60639', '60707', '60302', '60644', '60304', '60607', '60608',\n",
       "       '60606', '60616', '60605', '60633', '60656', '60631', '60610',\n",
       "       '60611', '60602', '60601', '60657', '60603', '60649', '60619',\n",
       "       '60617', '60827', '60638', '60609', '60636', '60621', '60652',\n",
       "       '60453', '60660-1448', '60653', '60632', '60641', '60624', '60623',\n",
       "       '60628', '60411', '60629', '60620', '60643', '60202', '60805'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['review_scores_rating'].describe()\n",
    "df['zipcode'].unique()\n",
    "# def clean_zipcode(row):\n",
    "#     return row[:7]\n",
    "# df['zipcode'] = df.apply(clean_zipcode)\n",
    "# df['zipcode'].unique()\n",
    "\n",
    "# pd.to_numeric(df['zipcode'], errors = 'coerce')\n",
    "# df['zipcode'][df['zipcode'] == '60660-1448']\n",
    "# df['zipcode'] = df['zipcode'].apply(lambda x: str(x)[:6])\n",
    "# df['zipcode'].unique()\n",
    "# df['zipcode'].astype(float)\n",
    "# sns.distplot(df['zipcode'])\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjhuynh/anaconda3/lib/python3.6/site-packages/pysal/__init__.py:65: VisibleDeprecationWarning: PySAL's API will be changed on 2018-12-31. The last release made with this API is version 1.14.4. A preview of the next API version is provided in the `pysal` 2.0 prelease candidate. The API changes and a guide on how to change imports is provided at https://pysal.org/about\n",
      "  ), VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.702566, -73.816859)\n",
      "(40.70546, -73.810708)\n",
      "(40.709179, -73.820574)\n",
      "(40.700486, -73.807969)\n",
      "(40.694624, -73.820593)\n",
      "(40.695132, -73.820841)\n",
      "(40.694095, -73.821334)\n",
      "(40.694165, -73.822368)\n",
      "(40.695077, -73.822817)\n",
      "(40.6747769261, -73.8092618174)\n"
     ]
    }
   ],
   "source": [
    "import pysal\n",
    "from pysal.cg.kdtree import KDTree    \n",
    "\n",
    "locations = [(40.702566, -73.816859),\n",
    "         (40.70546, -73.810708),\n",
    "         (40.709179, -73.820574),\n",
    "         (40.700486, -73.807969),\n",
    "         (40.694624, -73.820593),\n",
    "         (40.695132, -73.820841),\n",
    "         (40.694095, -73.821334),\n",
    "         (40.694165, -73.822368),\n",
    "         (40.695077, -73.822817),\n",
    "         (40.6747769261, -73.8092618174)] \n",
    "tree = KDTree(locations, distance_metric='Arc', radius=pysal.cg.RADIUS_EARTH_MILES)\n",
    "current_point = (40.709523, -73.802472)\n",
    "# get all points within 1 mile of 'current_point'\n",
    "indices = tree.query_ball_point(current_point, 30)\n",
    "for i in indices:\n",
    "    print(locations[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEES and PRICES\n",
    "df['price'] = df['price'].str.replace(\"\\$|,\", \"\").astype(float)\n",
    "df['security_deposit'] = df['security_deposit'].str.replace(\"\\$|,\", \"\").astype(float)\n",
    "df['cleaning_fee'] = df['cleaning_fee'].str.replace(\"\\$|,\", \"\").astype(float)\n",
    "df['extra_people'] = df['extra_people'].str.replace(\"\\$|,\", \"\").astype(float)\n",
    "df['availability'] = df['availability_365'] / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that have 'NaN'in key features\n",
    "# solve NaN cells in unimportant attributes\n",
    "\n",
    "# remove_criteria = df['price'].isnull() | df['zipcode'].isnull()\n",
    "# df = df[-remove_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOUSE RULES\n",
    "house_rules = df['house_rules'].str.lower()\n",
    "\n",
    "smoking = house_rules.str.contains(\"smoke|smoking\", na= False)\n",
    "df.loc[:, 'smoking'] = - smoking # False: No smoking allowed\n",
    "\n",
    "pet = house_rules.str.contains(\"pet\", na=False)\n",
    "df.loc[:, 'pet'] = - pet\n",
    "\n",
    "party = house_rules.str.contains(\"party|parties\", na=False)\n",
    "df.loc[:, 'party'] = - party\n",
    "\n",
    "guest = house_rules.str.contains(\"guest|guests\", na=False)\n",
    "df.loc[:, 'guest'] = - guest\n",
    "\n",
    "df = df.drop(['house_rules'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# AMENITIES\n",
    "amenities = list(df['amenities'])\n",
    "total = ','.join(amenities)\n",
    "total = total.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\"\", \"\").split(\",\")\n",
    "amenity_items = list(set(total))\n",
    "amenity_items = list(filter(None, amenity_items))\n",
    "for item in amenity_items:\n",
    "    if re.match(r'translation',item):\n",
    "        amenity_items.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Amenities into OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "amenities = list(df['amenities'])\n",
    "# print(amenity_items)\n",
    "# amenities\n",
    "# df['amenities'].value_counts()\n",
    "new_table = pd.DataFrame(index = df.reset_index().values[:,0], columns = amenity_items).fillna(0)\n",
    "# new_table.head()\n",
    "for i in range(len(amenities)):\n",
    "    for item in amenity_items:\n",
    "        if item in amenities[i]:\n",
    "            new_table.set_value(i, item, 1)\n",
    "sum_table = np.array(new_table.sum())\n",
    "ind = (-sum_table).argsort()[:60]\n",
    "sort_table = new_table.sum().iloc[ind]\n",
    "df = df.drop(['amenities'], axis = 1)\n",
    "df = pd.concat([df, sort_table], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce list of amenities\n",
    "\n",
    "# fill NaN with most frequent values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df['host_response_time'].iloc[5204])\n",
    "column_list = list(df['host_response_time'])\n",
    "len(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values =list(df['host_response_time'].unique())[:-1]\n",
    "unique_values\n",
    "column_list = list(df['host_response_time'])\n",
    "new_table = pd.DataFrame(index = df.reset_index().values[:,0], columns = unique_values).fillna(0)\n",
    "new_table.head()\n",
    "for i in range(len( df )):\n",
    "        for item in unique_values:\n",
    "            print((item,i))\n",
    "            if item in column_list[i] and pd.isnull(column_list[i])==False:\n",
    "                new_table.set_value(i, item, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bed_type', 'room_type', 'cancellation_policy', 'property_type', 'host_response_time']\n",
    "\n",
    "for column in columns:  \n",
    "    unique_values = list(df[column].unique())\n",
    "    column_list = list(df[column])\n",
    "    new_table = pd.DataFrame(index = df.reset_index().values[:,0], columns = unique_values).fillna(0)\n",
    "    \n",
    "    for i in range(len( column_list )):\n",
    "        for item in unique_values:\n",
    "            if item in column_list[i]:\n",
    "                new_table.set_value(i, item, 1)  \n",
    "    df = pd.concat( [df, new_table], axis = 1)\n",
    "    df = df.drop([column], axis = 1)         \n",
    "# df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'date'\tneighborhood\tSafety of neighborhood\tVariable cost\tInitial Investment\tAccomodation\tCapacity\tPrice per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# df['cancellation_policy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cluster_data=df.ix[:,2:]\n",
    "X=cluster_data\n",
    "y=df.ix[:,'price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "tunedParameters=[{'n_estimators':range(50,100,10)}]\n",
    "clf=GridSearchCV(RandomForestRegressor(n_jobs = -1, criterion='mse'), param_grid = tunedParameters,cv=10)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cluster_data\n",
    "y=df.ix[:,'price']\n",
    "from collections import OrderedDict\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "ensemble_clfs = [(\"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestClassifier(warm_start=True, max_features=None,\n",
    "                               oob_score=True,\n",
    "                               random_state=0))]\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 10\n",
    "max_estimators = 100\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X=cluster_data\n",
    "y=df.ix[:,'price']\n",
    "tunedParameters = [{'n_estimators':100}]\n",
    "\n",
    "clf2 = RandomForestRegressor(n_jobs = 1, criterion='mse', n_estimators=100)\n",
    "#Fit Model\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatImp = pd.DataFrame({'feature': list(X.columns), 'importance': list(clf2.feature_importances_)})\n",
    "FeatImp = FeatImp.sort_values('importance', ascending = False)\n",
    "#Set Index To Field You want to Sort Bar Chart By\n",
    "FeatImp = FeatImp.set_index('feature')\n",
    "FeatImp.head(100)\n",
    "FeatImp.to_csv('feature_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatImp.index[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatImp['importance'].values[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"Feature Importance\")\n",
    "y_pos = np.arange(len(FeatImp.index[0:30]))\n",
    "plt.bar(y_pos,FeatImp['importance'].values[0:30])\n",
    "plt.xticks(y_pos, FeatImp.index[0:30],rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.figure(figsize=(17,10))\n",
    "# df['price'] = df.price.str.replace(\"\\$|,\", \"\").astype(float)\n",
    "# df['price'].hist()\n",
    "sns.distplot(df['price'])\n",
    "# plt.show()\n",
    "mean_price = df.price.iloc[:5].mean()\n",
    "mean_price\n",
    "# df['host_acceptance_rate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review_scores_rating'].fillna(0, inplace=True)\n",
    "df['review_scores_rating'].dropna(axis=0, inplace=True)\n",
    "sns.distplot(df['review_scores_rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Plot\n",
    "var = 'review_scores_rating'\n",
    "data = pd.concat([df['price'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='price')\n",
    "data.plot.scatter(x=var, y='price', ylim=(0,1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster by locations\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def plot_3D_clusters(X, k):\n",
    "    \"\"\"Plot 3 attributes in dataset to explore natural clusters within data\"\"\"\n",
    "    estimators = {'k_means_3': KMeans(n_clusters=k)}\n",
    "    fignum = 1\n",
    "    for name, est in estimators.items():\n",
    "        fig = plt.figure(fignum, figsize=(4, 3))\n",
    "        plt.clf()\n",
    "        ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "        plt.cla()\n",
    "        est.fit(X)\n",
    "        labels = est.labels_\n",
    "        # Change the 2nd column in X[:,_] to choose attributes for plotting\n",
    "        ax.scatter(X[:,0], X[:,1], X[:,2], c=labels.astype(np.float),edgecolor='k')\n",
    "        ax.w_xaxis.set_ticklabels([])\n",
    "        ax.w_yaxis.set_ticklabels([])\n",
    "        ax.w_zaxis.set_ticklabels([])\n",
    "        ax.set_xlabel('latitude')\n",
    "        ax.set_ylabel('longitude')\n",
    "        ax.set_zlabel('price')\n",
    "        fignum = fignum + 1\n",
    "    plt.show()\n",
    "# change the n\n",
    "df = pd.read_csv('Airbnb_data/listings_SanFan.csv')\n",
    "df['price'] = df['price'].str.replace(\"\\$|,\", \"\").astype(float)\n",
    "X = np.array(df[['latitude', 'longitude', 'price']])\n",
    "plot_3D_clusters(X, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression model\n",
    "import statsmodels.api as sm # import statsmodels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].describe()\n",
    "df['host_acceptance_rate'].describe()\n",
    "df['host_response_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "# right skewed: log transform\n",
    "# left skewed: power transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data\n",
    "train_df, test_df = \n",
    "norm_\n",
    "norm_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborRegressor\n",
    "# Create KNN model: 5 closest neighbors\n",
    "knn = KNeighborRegressor(algorithm='brute', n_neighbors = 5)\n",
    "cols = ['accommodates', 'bedrooms', 'bathrooms', 'beds']\n",
    "knn.fit(norm_train_df[col], norm_train_df['price'])\n",
    "features_predictions = knn.predict(norm_test_df[cols])\n",
    "features_mse = mean_squared_error(norm_test_df['price'], features_predictions)\n",
    "features_rmse = features_mse ** (1/2)\n",
    "features_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
